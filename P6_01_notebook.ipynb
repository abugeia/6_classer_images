{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<!-- omit in toc -->\r\n",
    "# questions\r\n",
    "\r\n",
    "* programme python qui prend une image array en entrée ?\r\n",
    "  terminal script.py + argument par ex l'image\r\n",
    "  $ python script.py --file pah_to_image.png\r\n",
    "  argparse librairie (pré installée)\r\n",
    "* critères d'évaluation\r\n",
    "* ok\r\n",
    "* Google colab ? \r\n",
    "  oui pour éviter l'installation de drivers gpu etc\r\n",
    "* AWS ?\r\n",
    "  Chronophage pour la pratique\r\n",
    "* Quels doc utiliser pour le dataset ?\r\n",
    "* Comment recupérer les labels ?\r\n",
    "  xml\r\n",
    "* git à initilize + github\r\n",
    "\r\n",
    "pour charger le dataset\r\n",
    "os + boucle (list dir)\r\n",
    "\r\n",
    "\r\n",
    "<!-- omit in toc -->\r\n",
    "# Classez des images à l'aide d'algorithmes de Deep Learning\r\n",
    "\r\n",
    "<!-- omit in toc -->\r\n",
    "# sommaire\r\n",
    "\r\n",
    "- [1. Problématique](#1-problématique)\r\n",
    "- [2. Cleaning](#2-cleaning)\r\n",
    "- [3. Exploration](#3-exploration)\r\n",
    "- [4. feature engineering](#4-feature-engineering)\r\n",
    "\r\n",
    "# 1. Problématique\r\n",
    "\r\n",
    "Obtenir un algorithme capable de classer les images en fonction de la race du chien présent sur l'image.\r\n",
    "\r\n",
    "**Ressources**\r\n",
    "vous entraînerez votre algorithme en utilisant le Stanford Dogs Dataset.\r\n",
    "\r\n",
    "**Processus**\r\n",
    "1. pré-processer des images avec des techniques spécifiques (e.g. whitening, equalization, éventuellement modification de la taille des images)\r\n",
    "2. réaliser de la data augmentation (mirroring, cropping...).\r\n",
    "3. mettre en œuvre deux approches s’appuyant sur l’état de l’art et l’utilisation de CNN (réseaux de neurones convolutionnels) à comparer en termes de temps de traitement et de résultat\r\n",
    "   1. Une première en réalisant votre propre réseau CNN, en vous inspirant de réseaux CNN existants. Prenez soin d'optimiser certains hyperparamètres (des layers du modèle, de la compilation du modèle et de l’exécution du modèle)\r\n",
    "   2. Une deuxième en utilisant le transfer learning, c’est-à-dire en utilisant un réseau déjà entraîné, et en le modifiant pour répondre à votre problème.\r\n",
    "\r\n",
    "\r\n",
    "transfer learning\r\n",
    "\r\n",
    "obligatoire : réentraîner les dernières couches pour prédire les classes qui vous intéressent seulement.\r\n",
    "Il est également possible d’adapter la structure (supprimer certaines couches, par exemple) ou de réentraîner le modèle avec un très faible learning rate pour ajuster les poids à votre problème (plus long) et optimiser les performances.\r\n",
    "\r\n",
    "Ressources de calcul\r\n",
    "\r\n",
    "Limitez le jeu de données, en ne sélectionnant que quelques classes (races de chiens), ce qui permettra déjà de tester la démarche et la conception des modèles, avant une éventuelle généralisation.\r\n",
    "Utilisez la carte graphique de l’ordinateur en tant que GPU (l'installation est un peu fastidieuse, et l'ordinateur est inutilisable le temps du calcul).\r\n",
    "C'est l'occasion de vous initier au cloud computing, qui permet d'avoir temporairement accès à des machines très puissantes, en étant facturé seulement durant le temps d'utilisation. Le plus connu est AWS, mais d'autres existent (Google, Microsoft...).\r\n",
    "\r\n",
    "Vous pouvez tester également Google Colaboratory qui permet de mettre en œuvre gratuitement des réseaux CNN utilisant de la GPU.\r\n",
    "\r\n",
    "Ressources complémentaires\r\n",
    "1) Prétraitement des images \r\n",
    "le whitening.\r\n",
    "data augmentation (utile ou pas ?)\r\n",
    "l’equalization.\r\n",
    "1) CNN et transfer learning\r\n",
    "Guide d’utilisation de Google Colaboratory avec GPU.\r\n",
    "\r\n",
    "computer vision (ingé spé)\r\n",
    "traiter les données qui proviennent d'une camera\r\n",
    "\r\n",
    "Maitriser le preprocesing + CNN (structure, pbtique optimisation diff hyperprmptr)\r\n",
    "transfer learning \r\n",
    "\r\n",
    "comparer CNN  et transfer learning \r\n",
    "\r\n",
    "accuracy score bpour évaluer ?\r\n",
    "mesurer l'apport du preprocessing dans les resultats du modèle\r\n",
    "\r\n",
    "\r\n",
    "mettre en oeuvre techniques de data augmentation\r\n",
    "   algo gourmand en donnée pour\r\n",
    "   à partir d'une image en créer plusieurs copies avec transformations pour que le modèle en connaisse plsueiurs formes \r\n",
    "\r\n",
    "   dans keras image.datagenerator\r\n",
    "\r\n",
    "   20000 fichiers 120 races\r\n",
    "   160 photos/race\r\n",
    "\r\n",
    "Simulations pour opti le modèle (layers, etc)\r\n",
    "Limiter le nb de classes pour réduire tps de traitement\r\n",
    "\r\n",
    "sélectionner un modèle DL adapté\r\n",
    "Champ d'application de classification\r\n",
    "Au moins 2 modèles CNN \r\n",
    "au moins un modèle CNN transfer learning tel que VGG16, ResNet50, ou Inception ResNetV2\r\n",
    "\r\n",
    "séparation train, test (mais sans sklearn ?)\r\n",
    "\r\n",
    "kernel size, drop out, methode activation layer final\r\n",
    "Expliquer au fur et à mesure ce qui est utilisé\r\n",
    "\r\n",
    "adapter\r\n",
    "optimizer, loss, sgd adam\r\n",
    "batch size, nb d'epochs\r\n",
    "\r\n",
    "résultats comparés de manière auto\r\n",
    "\r\n",
    "transformation des variables\r\n",
    "openCV (traitement d'image, analog sklearn etc)\r\n",
    "cropping, whitening, equalizer, débruitage, redimentionnement, miroring\r\n",
    "\r\n",
    "montrer un exmple avant/après pour un des traitements\r\n",
    "\r\n",
    "\r\n",
    "# 2. Cleaning\r\n",
    "\r\n",
    "# 3. Exploration\r\n",
    "\r\n",
    "# 4. feature engineering\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Generic librairies\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "# import seaborn as sns\r\n",
    "# from IPython.display import display, HTML\r\n",
    "from IPython.core.interactiveshell import InteractiveShell\r\n",
    "\r\n",
    "# Activate multi output\r\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\r\n",
    "\r\n",
    "# # For jupyter NB users \r\n",
    "# # set size of window\r\n",
    "# display(HTML(data=\"\"\"\r\n",
    "# <style>\r\n",
    "#     div#notebook-container    { width: 95%; }\r\n",
    "#     div#menubar-container     { width: 65%; }\r\n",
    "#     div#maintoolbar-container { width: 99%; }\r\n",
    "# </style>\r\n",
    "# \"\"\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}